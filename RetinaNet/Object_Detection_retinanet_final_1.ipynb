{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prepare_Data.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/amitnits2016/Keras/blob/master/RetinaNet/Object_Detection_retinanet_final.ipynb",
      "authorship_tag": "ABX9TyN4RB32BgPrBdlmcabuNfIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitnits2016/Keras/blob/master/RetinaNet/Object_Detection_retinanet_final_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbeGTuKDp_wX",
        "colab_type": "text"
      },
      "source": [
        "#### Our Google Drive should have Data Folder, resnet50_coco_best_v2.0.1.h5 and data_load.py file\n",
        "\n",
        "#### Our data contains three objects:\n",
        "1. chair \n",
        "2. table \n",
        "3. vase\n",
        "\n",
        "#### Mount Google Drive to add Data Folder, In which Two separate folders Train and Test will be there. Each Folder is containing 3 files:\n",
        "1. jpg file  (Train: 167, Test: 55)\n",
        "2. xml file  (Train: 167, Test: 55)\n",
        "3. text file (Train: 167, Test: 55)\n",
        "\n",
        "#### The folders will also contain a class file where each object is labelled. (Train: 1, Test: 1)\n",
        "\n",
        "#### This way \n",
        "#### Train Folder will have 167*3+1=502 files total\n",
        "#### Test Folder will have 55*3+1=166 files total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di-zQk-zp4n3",
        "colab_type": "text"
      },
      "source": [
        "# Cloning keras-retinanet using below commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZNAuOG3-y3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c7d0761e-5e61-4b64-a35d-17e11faa60f9"
      },
      "source": [
        "!git clone https://github.com/fizyr/keras-retinanet.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-retinanet'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 5918 (delta 19), reused 18 (delta 10), pack-reused 5885\u001b[K\n",
            "Receiving objects: 100% (5918/5918), 13.42 MiB | 5.00 MiB/s, done.\n",
            "Resolving deltas: 100% (3983/3983), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQjMQuX2rDax",
        "colab_type": "text"
      },
      "source": [
        "### Check the directory folder, and go to keras-retinanet folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XybgnVgYAFM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac73aa08-8c1e-4a43-9972-51f7e6cbd141"
      },
      "source": [
        "cd keras-retinanet/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-retinanet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0umSJ7Zr1g2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "12c5509e-8d87-43da-80e9-cd358b6aa048"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  \u001b[0m\u001b[01;34mkeras_retinanet\u001b[0m/  requirements.txt  \u001b[01;34msnapshots\u001b[0m/\n",
            "\u001b[01;34mexamples\u001b[0m/        LICENSE           setup.cfg         \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mimages\u001b[0m/          README.md         setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnZbk09br3zC",
        "colab_type": "text"
      },
      "source": [
        "#### Drag and Drop data_load.py file of Google Drive into keras-retinanet folder\n",
        "#### Drag and Drop resnet50_coco_best_v2.0.1.h5 file of Google Drive into keras-retinanet/snapshots folder\n",
        "\n",
        "#### Check If It is moved properly or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpkY72o3sNMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c326642d-ebc0-4826-d164-911e9f8bdffe"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  \u001b[0m\u001b[01;34mimages\u001b[0m/           README.md         setup.py\n",
            "data_load.py     \u001b[01;34mkeras_retinanet\u001b[0m/  requirements.txt  \u001b[01;34msnapshots\u001b[0m/\n",
            "\u001b[01;34mexamples\u001b[0m/        LICENSE           setup.cfg         \u001b[01;34mtests\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlitWnf-Oo_O",
        "colab_type": "text"
      },
      "source": [
        "#### run the setup.py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN9inZbbAKHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "792c3b8d-10fe-4753-a9e6-20318ab236e4"
      },
      "source": [
        "!python3 setup.py build install"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet\n",
            "copying keras_retinanet/losses.py -> build/lib.linux-x86_64-3.6/keras_retinanet\n",
            "copying keras_retinanet/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet\n",
            "copying keras_retinanet/initializers.py -> build/lib.linux-x86_64-3.6/keras_retinanet\n",
            "creating build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/__init__.py -> build/lib.linux-x86_64-3.6/tests\n",
            "copying tests/test_losses.py -> build/lib.linux-x86_64-3.6/tests\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/retinanet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/senet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/mobilenet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/resnet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/vgg.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/densenet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "copying keras_retinanet/models/effnet.py -> build/lib.linux-x86_64-3.6/keras_retinanet/models\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/layers\n",
            "copying keras_retinanet/layers/filter_detections.py -> build/lib.linux-x86_64-3.6/keras_retinanet/layers\n",
            "copying keras_retinanet/layers/_misc.py -> build/lib.linux-x86_64-3.6/keras_retinanet/layers\n",
            "copying keras_retinanet/layers/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/layers\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/callbacks\n",
            "copying keras_retinanet/callbacks/common.py -> build/lib.linux-x86_64-3.6/keras_retinanet/callbacks\n",
            "copying keras_retinanet/callbacks/eval.py -> build/lib.linux-x86_64-3.6/keras_retinanet/callbacks\n",
            "copying keras_retinanet/callbacks/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/callbacks\n",
            "copying keras_retinanet/callbacks/coco.py -> build/lib.linux-x86_64-3.6/keras_retinanet/callbacks\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/gpu.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/coco_eval.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/keras_version.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/image.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/colors.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/eval.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/model.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/tf_version.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/visualization.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/anchors.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/transform.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "copying keras_retinanet/utils/config.py -> build/lib.linux-x86_64-3.6/keras_retinanet/utils\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/theano_backend.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/tensorflow_backend.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/dynamic.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/common.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "copying keras_retinanet/backend/cntk_backend.py -> build/lib.linux-x86_64-3.6/keras_retinanet/backend\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/generator.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/pascal_voc.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/open_images.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/kitti.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/coco.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "copying keras_retinanet/preprocessing/csv_generator.py -> build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing\n",
            "creating build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "copying keras_retinanet/bin/debug.py -> build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "copying keras_retinanet/bin/__init__.py -> build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "copying keras_retinanet/bin/train.py -> build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "copying keras_retinanet/bin/convert_model.py -> build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "copying keras_retinanet/bin/evaluate.py -> build/lib.linux-x86_64-3.6/keras_retinanet/bin\n",
            "creating build/lib.linux-x86_64-3.6/tests/models\n",
            "copying tests/models/test_mobilenet.py -> build/lib.linux-x86_64-3.6/tests/models\n",
            "copying tests/models/test_densenet.py -> build/lib.linux-x86_64-3.6/tests/models\n",
            "copying tests/models/__init__.py -> build/lib.linux-x86_64-3.6/tests/models\n",
            "creating build/lib.linux-x86_64-3.6/tests/layers\n",
            "copying tests/layers/test_misc.py -> build/lib.linux-x86_64-3.6/tests/layers\n",
            "copying tests/layers/test_filter_detections.py -> build/lib.linux-x86_64-3.6/tests/layers\n",
            "copying tests/layers/__init__.py -> build/lib.linux-x86_64-3.6/tests/layers\n",
            "creating build/lib.linux-x86_64-3.6/tests/utils\n",
            "copying tests/utils/test_anchors.py -> build/lib.linux-x86_64-3.6/tests/utils\n",
            "copying tests/utils/__init__.py -> build/lib.linux-x86_64-3.6/tests/utils\n",
            "copying tests/utils/test_transform.py -> build/lib.linux-x86_64-3.6/tests/utils\n",
            "creating build/lib.linux-x86_64-3.6/tests/backend\n",
            "copying tests/backend/test_common.py -> build/lib.linux-x86_64-3.6/tests/backend\n",
            "copying tests/backend/__init__.py -> build/lib.linux-x86_64-3.6/tests/backend\n",
            "creating build/lib.linux-x86_64-3.6/tests/preprocessing\n",
            "copying tests/preprocessing/test_generator.py -> build/lib.linux-x86_64-3.6/tests/preprocessing\n",
            "copying tests/preprocessing/__init__.py -> build/lib.linux-x86_64-3.6/tests/preprocessing\n",
            "copying tests/preprocessing/test_csv_generator.py -> build/lib.linux-x86_64-3.6/tests/preprocessing\n",
            "copying tests/preprocessing/test_image.py -> build/lib.linux-x86_64-3.6/tests/preprocessing\n",
            "running build_ext\n",
            "cythoning keras_retinanet/utils/compute_overlap.pyx to keras_retinanet/utils/compute_overlap.c\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/keras-retinanet/keras_retinanet/utils/compute_overlap.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'keras_retinanet.utils.compute_overlap' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/keras_retinanet\n",
            "creating build/temp.linux-x86_64-3.6/keras_retinanet/utils\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.6m -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -c keras_retinanet/utils/compute_overlap.c -o build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1832:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kkeras_retinanet/utils/compute_overlap.c:610\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.o -o build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating keras_retinanet.egg-info\n",
            "writing keras_retinanet.egg-info/PKG-INFO\n",
            "writing dependency_links to keras_retinanet.egg-info/dependency_links.txt\n",
            "writing entry points to keras_retinanet.egg-info/entry_points.txt\n",
            "writing requirements to keras_retinanet.egg-info/requires.txt\n",
            "writing top-level names to keras_retinanet.egg-info/top_level.txt\n",
            "writing manifest file 'keras_retinanet.egg-info/SOURCES.txt'\n",
            "writing manifest file 'keras_retinanet.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/retinanet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/senet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/mobilenet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/resnet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/vgg.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/densenet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/models/effnet.py -> build/bdist.linux-x86_64/egg/keras_retinanet/models\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/layers\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/layers/filter_detections.py -> build/bdist.linux-x86_64/egg/keras_retinanet/layers\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/layers/_misc.py -> build/bdist.linux-x86_64/egg/keras_retinanet/layers\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/layers/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/layers\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/losses.py -> build/bdist.linux-x86_64/egg/keras_retinanet\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/callbacks\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/callbacks/common.py -> build/bdist.linux-x86_64/egg/keras_retinanet/callbacks\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/callbacks/eval.py -> build/bdist.linux-x86_64/egg/keras_retinanet/callbacks\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/callbacks\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/callbacks/coco.py -> build/bdist.linux-x86_64/egg/keras_retinanet/callbacks\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/initializers.py -> build/bdist.linux-x86_64/egg/keras_retinanet\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/gpu.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/coco_eval.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/keras_version.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/image.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/colors.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/eval.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/model.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/tf_version.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/visualization.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/anchors.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/transform.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/config.py -> build/bdist.linux-x86_64/egg/keras_retinanet/utils\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/theano_backend.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/tensorflow_backend.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/dynamic.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/common.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/backend/cntk_backend.py -> build/bdist.linux-x86_64/egg/keras_retinanet/backend\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/generator.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/pascal_voc.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/open_images.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/kitti.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/coco.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/preprocessing/csv_generator.py -> build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing\n",
            "creating build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/bin/debug.py -> build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/bin/__init__.py -> build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/bin/train.py -> build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/bin/convert_model.py -> build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/bin/evaluate.py -> build/bdist.linux-x86_64/egg/keras_retinanet/bin\n",
            "creating build/bdist.linux-x86_64/egg/tests\n",
            "creating build/bdist.linux-x86_64/egg/tests/models\n",
            "copying build/lib.linux-x86_64-3.6/tests/models/test_mobilenet.py -> build/bdist.linux-x86_64/egg/tests/models\n",
            "copying build/lib.linux-x86_64-3.6/tests/models/test_densenet.py -> build/bdist.linux-x86_64/egg/tests/models\n",
            "copying build/lib.linux-x86_64-3.6/tests/models/__init__.py -> build/bdist.linux-x86_64/egg/tests/models\n",
            "creating build/bdist.linux-x86_64/egg/tests/layers\n",
            "copying build/lib.linux-x86_64-3.6/tests/layers/test_misc.py -> build/bdist.linux-x86_64/egg/tests/layers\n",
            "copying build/lib.linux-x86_64-3.6/tests/layers/test_filter_detections.py -> build/bdist.linux-x86_64/egg/tests/layers\n",
            "copying build/lib.linux-x86_64-3.6/tests/layers/__init__.py -> build/bdist.linux-x86_64/egg/tests/layers\n",
            "copying build/lib.linux-x86_64-3.6/tests/__init__.py -> build/bdist.linux-x86_64/egg/tests\n",
            "creating build/bdist.linux-x86_64/egg/tests/utils\n",
            "copying build/lib.linux-x86_64-3.6/tests/utils/test_anchors.py -> build/bdist.linux-x86_64/egg/tests/utils\n",
            "copying build/lib.linux-x86_64-3.6/tests/utils/__init__.py -> build/bdist.linux-x86_64/egg/tests/utils\n",
            "copying build/lib.linux-x86_64-3.6/tests/utils/test_transform.py -> build/bdist.linux-x86_64/egg/tests/utils\n",
            "copying build/lib.linux-x86_64-3.6/tests/test_losses.py -> build/bdist.linux-x86_64/egg/tests\n",
            "creating build/bdist.linux-x86_64/egg/tests/backend\n",
            "copying build/lib.linux-x86_64-3.6/tests/backend/test_common.py -> build/bdist.linux-x86_64/egg/tests/backend\n",
            "copying build/lib.linux-x86_64-3.6/tests/backend/__init__.py -> build/bdist.linux-x86_64/egg/tests/backend\n",
            "creating build/bdist.linux-x86_64/egg/tests/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/tests/preprocessing/test_generator.py -> build/bdist.linux-x86_64/egg/tests/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/tests/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/tests/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/tests/preprocessing/test_csv_generator.py -> build/bdist.linux-x86_64/egg/tests/preprocessing\n",
            "copying build/lib.linux-x86_64-3.6/tests/preprocessing/test_image.py -> build/bdist.linux-x86_64/egg/tests/preprocessing\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/retinanet.py to retinanet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/senet.py to senet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/mobilenet.py to mobilenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/resnet.py to resnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/vgg.py to vgg.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/densenet.py to densenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/models/effnet.py to effnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/layers/filter_detections.py to filter_detections.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/layers/_misc.py to _misc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/losses.py to losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/callbacks/common.py to common.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/callbacks/eval.py to eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/callbacks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/callbacks/coco.py to coco.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/initializers.py to initializers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/gpu.py to gpu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/coco_eval.py to coco_eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/keras_version.py to keras_version.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/image.py to image.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/colors.py to colors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/eval.py to eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/tf_version.py to tf_version.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/visualization.py to visualization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/anchors.py to anchors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/transform.py to transform.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/theano_backend.py to theano_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/tensorflow_backend.py to tensorflow_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/dynamic.py to dynamic.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/common.py to common.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/backend/cntk_backend.py to cntk_backend.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/generator.py to generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/pascal_voc.py to pascal_voc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/open_images.py to open_images.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/kitti.py to kitti.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/coco.py to coco.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/preprocessing/csv_generator.py to csv_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/bin/debug.py to debug.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/bin/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/bin/train.py to train.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/bin/convert_model.py to convert_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/bin/evaluate.py to evaluate.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/models/test_mobilenet.py to test_mobilenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/models/test_densenet.py to test_densenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/layers/test_misc.py to test_misc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/layers/test_filter_detections.py to test_filter_detections.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/layers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/utils/test_anchors.py to test_anchors.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/utils/test_transform.py to test_transform.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/test_losses.py to test_losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/backend/test_common.py to test_common.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/backend/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/preprocessing/test_generator.py to test_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/preprocessing/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/preprocessing/test_csv_generator.py to test_csv_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/preprocessing/test_image.py to test_image.cpython-36.pyc\n",
            "creating stub loader for keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/keras_retinanet/utils/compute_overlap.py to compute_overlap.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying keras_retinanet.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "keras_retinanet.bin.__pycache__.convert_model.cpython-36: module references __file__\n",
            "keras_retinanet.bin.__pycache__.debug.cpython-36: module references __file__\n",
            "keras_retinanet.bin.__pycache__.evaluate.cpython-36: module references __file__\n",
            "keras_retinanet.bin.__pycache__.train.cpython-36: module references __file__\n",
            "keras_retinanet.utils.__pycache__.compute_overlap.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/keras_retinanet-0.5.1-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing keras_retinanet-0.5.1-py3.6-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/keras_retinanet-0.5.1-py3.6-linux-x86_64.egg\n",
            "Extracting keras_retinanet-0.5.1-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding keras-retinanet 0.5.1 to easy-install.pth file\n",
            "Installing retinanet-convert-model script to /usr/local/bin\n",
            "Installing retinanet-debug script to /usr/local/bin\n",
            "Installing retinanet-evaluate script to /usr/local/bin\n",
            "Installing retinanet-train script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/keras_retinanet-0.5.1-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for keras-retinanet==0.5.1\n",
            "Searching for keras-resnet==0.1.0\n",
            "Reading https://pypi.org/simple/keras-resnet/\n",
            "Downloading https://files.pythonhosted.org/packages/05/46/ad0b2d1a05d9497bd80c98a2c3f4d8be38a4601ace69af72814f5fafd851/keras-resnet-0.1.0.tar.gz#sha256=65a55f1c184e38d388cc2295ea4170475fe060d504d7e7950c255b81d72a0dfb\n",
            "Best match: keras-resnet 0.1.0\n",
            "Processing keras-resnet-0.1.0.tar.gz\n",
            "Writing /tmp/easy_install-ltt1p2ng/keras-resnet-0.1.0/setup.cfg\n",
            "Running keras-resnet-0.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-ltt1p2ng/keras-resnet-0.1.0/egg-dist-tmp-gglyin2_\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving keras_resnet-0.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding keras-resnet 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/keras_resnet-0.1.0-py3.6.egg\n",
            "Searching for progressbar2==3.38.0\n",
            "Best match: progressbar2 3.38.0\n",
            "Adding progressbar2 3.38.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opencv-python==4.1.2.30\n",
            "Best match: opencv-python 4.1.2.30\n",
            "Adding opencv-python 4.1.2.30 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Cython==0.29.21\n",
            "Best match: Cython 0.29.21\n",
            "Adding Cython 0.29.21 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras==2.3.1\n",
            "Best match: Keras 2.3.1\n",
            "Adding Keras 2.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-utils==2.4.0\n",
            "Best match: python-utils 2.4.0\n",
            "Adding python-utils 2.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.5\n",
            "Best match: numpy 1.18.5\n",
            "Adding numpy 1.18.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Applications==1.0.8\n",
            "Best match: Keras-Applications 1.0.8\n",
            "Adding Keras-Applications 1.0.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Keras-Preprocessing==1.1.2\n",
            "Best match: Keras-Preprocessing 1.1.2\n",
            "Adding Keras-Preprocessing 1.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for h5py==2.10.0\n",
            "Best match: h5py 2.10.0\n",
            "Adding h5py 2.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for keras-retinanet==0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nqkSIg_NE_t",
        "colab_type": "text"
      },
      "source": [
        "#### Modify the ./keras_retinanet/bin/train.py file, so that more than 5 epochs can be run without stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCMMoKAOkEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat ./keras_retinanet/bin/train.py"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv2HBy8xbIzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8024914e-bc17-473c-fe9c-637f5cb07ae6"
      },
      "source": [
        "%%writefile /content/keras-retinanet/keras_retinanet/bin/train.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"\n",
        "Copyright 2017-2018 Fizyr (https://fizyr.com)\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "import keras\n",
        "import keras.preprocessing.image\n",
        "import tensorflow as tf\n",
        "\n",
        "# Allow relative imports when being executed as script.\n",
        "if __name__ == \"__main__\" and __package__ is None:\n",
        "    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))\n",
        "    import keras_retinanet.bin  # noqa: F401\n",
        "    __package__ = \"keras_retinanet.bin\"\n",
        "\n",
        "# Change these to absolute imports if you copy this script outside the keras_retinanet package.\n",
        "from .. import layers  # noqa: F401\n",
        "from .. import losses\n",
        "from .. import models\n",
        "from ..callbacks import RedirectModel\n",
        "from ..callbacks.eval import Evaluate\n",
        "from ..models.retinanet import retinanet_bbox\n",
        "from ..preprocessing.csv_generator import CSVGenerator\n",
        "from ..preprocessing.kitti import KittiGenerator\n",
        "from ..preprocessing.open_images import OpenImagesGenerator\n",
        "from ..preprocessing.pascal_voc import PascalVocGenerator\n",
        "from ..utils.anchors import make_shapes_callback\n",
        "from ..utils.config import read_config_file, parse_anchor_parameters, parse_pyramid_levels\n",
        "from ..utils.gpu import setup_gpu\n",
        "from ..utils.image import random_visual_effect_generator\n",
        "from ..utils.keras_version import check_keras_version\n",
        "from ..utils.model import freeze as freeze_model\n",
        "from ..utils.tf_version import check_tf_version\n",
        "from ..utils.transform import random_transform_generator\n",
        "\n",
        "\n",
        "def makedirs(path):\n",
        "    # Intended behavior: try to create the directory,\n",
        "    # pass if the directory exists already, fails otherwise.\n",
        "    # Meant for Python 2.7/3.n compatibility.\n",
        "    try:\n",
        "        os.makedirs(path)\n",
        "    except OSError:\n",
        "        if not os.path.isdir(path):\n",
        "            raise\n",
        "\n",
        "\n",
        "def model_with_weights(model, weights, skip_mismatch):\n",
        "    \"\"\" Load weights for model.\n",
        "\n",
        "    Args\n",
        "        model         : The model to load weights for.\n",
        "        weights       : The weights to load.\n",
        "        skip_mismatch : If True, skips layers whose shape of weights doesn't match with the model.\n",
        "    \"\"\"\n",
        "    if weights is not None:\n",
        "        model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_models(backbone_retinanet, num_classes, weights, multi_gpu=0,\n",
        "                  freeze_backbone=False, lr=1e-5, config=None):\n",
        "    \"\"\" Creates three models (model, training_model, prediction_model).\n",
        "\n",
        "    Args\n",
        "        backbone_retinanet : A function to call to create a retinanet model with a given backbone.\n",
        "        num_classes        : The number of classes to train.\n",
        "        weights            : The weights to load into the model.\n",
        "        multi_gpu          : The number of GPUs to use for training.\n",
        "        freeze_backbone    : If True, disables learning for the backbone.\n",
        "        config             : Config parameters, None indicates the default configuration.\n",
        "\n",
        "    Returns\n",
        "        model            : The base model. This is also the model that is saved in snapshots.\n",
        "        training_model   : The training model. If multi_gpu=0, this is identical to model.\n",
        "        prediction_model : The model wrapped with utility functions to perform object detection (applies regression values and performs NMS).\n",
        "    \"\"\"\n",
        "\n",
        "    modifier = freeze_model if freeze_backbone else None\n",
        "\n",
        "    # load anchor parameters, or pass None (so that defaults will be used)\n",
        "    anchor_params = None\n",
        "    num_anchors   = None\n",
        "    pyramid_levels = None\n",
        "    if config and 'anchor_parameters' in config:\n",
        "        anchor_params = parse_anchor_parameters(config)\n",
        "        num_anchors   = anchor_params.num_anchors()\n",
        "    if config and 'pyramid_levels' in config:\n",
        "        pyramid_levels = parse_pyramid_levels(config)\n",
        "\n",
        "    # Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.\n",
        "    # optionally wrap in a parallel model\n",
        "    if multi_gpu > 1:\n",
        "        from keras.utils import multi_gpu_model\n",
        "        with tf.device('/cpu:0'):\n",
        "            model = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier, pyramid_levels=pyramid_levels), weights=weights, skip_mismatch=True)\n",
        "        training_model = multi_gpu_model(model, gpus=multi_gpu)\n",
        "    else:\n",
        "        model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier, pyramid_levels=pyramid_levels), weights=weights, skip_mismatch=True)\n",
        "        training_model = model\n",
        "\n",
        "    # make prediction model\n",
        "    prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params, pyramid_levels=pyramid_levels)\n",
        "\n",
        "    # compile model\n",
        "    training_model.compile(\n",
        "        loss={\n",
        "            'regression'    : losses.smooth_l1(),\n",
        "            'classification': losses.focal()\n",
        "        },\n",
        "        optimizer=keras.optimizers.adam(lr=lr, clipnorm=0.001)\n",
        "    )\n",
        "\n",
        "    return model, training_model, prediction_model\n",
        "\n",
        "\n",
        "def create_callbacks(model, training_model, prediction_model, validation_generator, args):\n",
        "    \"\"\" Creates the callbacks to use during training.\n",
        "\n",
        "    Args\n",
        "        model: The base model.\n",
        "        training_model: The model that is used for training.\n",
        "        prediction_model: The model that should be used for validation.\n",
        "        validation_generator: The generator for creating validation data.\n",
        "        args: parseargs args object.\n",
        "\n",
        "    Returns:\n",
        "        A list of callbacks used for training.\n",
        "    \"\"\"\n",
        "    callbacks = []\n",
        "\n",
        "    tensorboard_callback = None\n",
        "\n",
        "    if args.tensorboard_dir:\n",
        "        makedirs(args.tensorboard_dir)\n",
        "        tensorboard_callback = keras.callbacks.TensorBoard(\n",
        "            log_dir                = args.tensorboard_dir,\n",
        "            histogram_freq         = 0,\n",
        "            batch_size             = args.batch_size,\n",
        "            write_graph            = True,\n",
        "            write_grads            = False,\n",
        "            write_images           = False,\n",
        "            embeddings_freq        = 0,\n",
        "            embeddings_layer_names = None,\n",
        "            embeddings_metadata    = None\n",
        "        )\n",
        "\n",
        "    if args.evaluation and validation_generator:\n",
        "        if args.dataset_type == 'coco':\n",
        "            from ..callbacks.coco import CocoEval\n",
        "\n",
        "            # use prediction model for evaluation\n",
        "            evaluation = CocoEval(validation_generator, tensorboard=tensorboard_callback)\n",
        "        else:\n",
        "            evaluation = Evaluate(validation_generator, tensorboard=tensorboard_callback, weighted_average=args.weighted_average)\n",
        "        evaluation = RedirectModel(evaluation, prediction_model)\n",
        "        callbacks.append(evaluation)\n",
        "\n",
        "    # save the model\n",
        "    if args.snapshots:\n",
        "        # ensure directory created first; otherwise h5py will error after epoch.\n",
        "        makedirs(args.snapshot_path)\n",
        "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "            os.path.join(\n",
        "                args.snapshot_path,\n",
        "                '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=args.backbone, dataset_type=args.dataset_type)\n",
        "            ),\n",
        "            verbose=1,\n",
        "            # save_best_only=True,\n",
        "            # monitor=\"mAP\",\n",
        "            # mode='max'\n",
        "        )\n",
        "        checkpoint = RedirectModel(checkpoint, model)\n",
        "        callbacks.append(checkpoint)\n",
        "\n",
        "    callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor    = 'loss',\n",
        "        factor     = args.reduce_lr_factor,\n",
        "        patience   = args.reduce_lr_patience,\n",
        "        verbose    = 1,\n",
        "        mode       = 'auto',\n",
        "        min_delta  = 0.0001,\n",
        "        cooldown   = 0,\n",
        "        min_lr     = 0\n",
        "    ))\n",
        "\n",
        "    if args.evaluation and validation_generator:\n",
        "        callbacks.append(keras.callbacks.EarlyStopping(\n",
        "            monitor    = 'mAP',\n",
        "            patience   = 5,\n",
        "            mode       = 'max',\n",
        "            min_delta  = 0.01\n",
        "        ))\n",
        "\n",
        "    if args.tensorboard_dir:\n",
        "        callbacks.append(tensorboard_callback)\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "\n",
        "def create_generators(args, preprocess_image):\n",
        "    \"\"\" Create generators for training and validation.\n",
        "\n",
        "    Args\n",
        "        args             : parseargs object containing configuration for generators.\n",
        "        preprocess_image : Function that preprocesses an image for the network.\n",
        "    \"\"\"\n",
        "    common_args = {\n",
        "        'batch_size'       : args.batch_size,\n",
        "        'config'           : args.config,\n",
        "        'image_min_side'   : args.image_min_side,\n",
        "        'image_max_side'   : args.image_max_side,\n",
        "        'no_resize'        : args.no_resize,\n",
        "        'preprocess_image' : preprocess_image,\n",
        "    }\n",
        "\n",
        "    # create random transform generator for augmenting training data\n",
        "    if args.random_transform:\n",
        "        transform_generator = random_transform_generator(\n",
        "            min_rotation=-0.1,\n",
        "            max_rotation=0.1,\n",
        "            min_translation=(-0.1, -0.1),\n",
        "            max_translation=(0.1, 0.1),\n",
        "            min_shear=-0.1,\n",
        "            max_shear=0.1,\n",
        "            min_scaling=(0.9, 0.9),\n",
        "            max_scaling=(1.1, 1.1),\n",
        "            flip_x_chance=0.5,\n",
        "            flip_y_chance=0.5,\n",
        "        )\n",
        "        visual_effect_generator = random_visual_effect_generator(\n",
        "            contrast_range=(0.9, 1.1),\n",
        "            brightness_range=(-.1, .1),\n",
        "            hue_range=(-0.05, 0.05),\n",
        "            saturation_range=(0.95, 1.05)\n",
        "        )\n",
        "    else:\n",
        "        transform_generator = random_transform_generator(flip_x_chance=0.5)\n",
        "        visual_effect_generator = None\n",
        "\n",
        "    if args.dataset_type == 'coco':\n",
        "        # import here to prevent unnecessary dependency on cocoapi\n",
        "        from ..preprocessing.coco import CocoGenerator\n",
        "\n",
        "        train_generator = CocoGenerator(\n",
        "            args.coco_path,\n",
        "            'train2017',\n",
        "            transform_generator=transform_generator,\n",
        "            visual_effect_generator=visual_effect_generator,\n",
        "            **common_args\n",
        "        )\n",
        "\n",
        "        validation_generator = CocoGenerator(\n",
        "            args.coco_path,\n",
        "            'val2017',\n",
        "            shuffle_groups=False,\n",
        "            **common_args\n",
        "        )\n",
        "    elif args.dataset_type == 'pascal':\n",
        "        train_generator = PascalVocGenerator(\n",
        "            args.pascal_path,\n",
        "            'train',\n",
        "            image_extension=args.image_extension,\n",
        "            transform_generator=transform_generator,\n",
        "            visual_effect_generator=visual_effect_generator,\n",
        "            **common_args\n",
        "        )\n",
        "\n",
        "        validation_generator = PascalVocGenerator(\n",
        "            args.pascal_path,\n",
        "            'val',\n",
        "            image_extension=args.image_extension,\n",
        "            shuffle_groups=False,\n",
        "            **common_args\n",
        "        )\n",
        "    elif args.dataset_type == 'csv':\n",
        "        train_generator = CSVGenerator(\n",
        "            args.annotations,\n",
        "            args.classes,\n",
        "            transform_generator=transform_generator,\n",
        "            visual_effect_generator=visual_effect_generator,\n",
        "            **common_args\n",
        "        )\n",
        "\n",
        "        if args.val_annotations:\n",
        "            validation_generator = CSVGenerator(\n",
        "                args.val_annotations,\n",
        "                args.classes,\n",
        "                shuffle_groups=False,\n",
        "                **common_args\n",
        "            )\n",
        "        else:\n",
        "            validation_generator = None\n",
        "    elif args.dataset_type == 'oid':\n",
        "        train_generator = OpenImagesGenerator(\n",
        "            args.main_dir,\n",
        "            subset='train',\n",
        "            version=args.version,\n",
        "            labels_filter=args.labels_filter,\n",
        "            annotation_cache_dir=args.annotation_cache_dir,\n",
        "            parent_label=args.parent_label,\n",
        "            transform_generator=transform_generator,\n",
        "            visual_effect_generator=visual_effect_generator,\n",
        "            **common_args\n",
        "        )\n",
        "\n",
        "        validation_generator = OpenImagesGenerator(\n",
        "            args.main_dir,\n",
        "            subset='validation',\n",
        "            version=args.version,\n",
        "            labels_filter=args.labels_filter,\n",
        "            annotation_cache_dir=args.annotation_cache_dir,\n",
        "            parent_label=args.parent_label,\n",
        "            shuffle_groups=False,\n",
        "            **common_args\n",
        "        )\n",
        "    elif args.dataset_type == 'kitti':\n",
        "        train_generator = KittiGenerator(\n",
        "            args.kitti_path,\n",
        "            subset='train',\n",
        "            transform_generator=transform_generator,\n",
        "            visual_effect_generator=visual_effect_generator,\n",
        "            **common_args\n",
        "        )\n",
        "\n",
        "        validation_generator = KittiGenerator(\n",
        "            args.kitti_path,\n",
        "            subset='val',\n",
        "            shuffle_groups=False,\n",
        "            **common_args\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError('Invalid data type received: {}'.format(args.dataset_type))\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "\n",
        "def check_args(parsed_args):\n",
        "    \"\"\" Function to check for inherent contradictions within parsed arguments.\n",
        "    For example, batch_size < num_gpus\n",
        "    Intended to raise errors prior to backend initialisation.\n",
        "\n",
        "    Args\n",
        "        parsed_args: parser.parse_args()\n",
        "\n",
        "    Returns\n",
        "        parsed_args\n",
        "    \"\"\"\n",
        "\n",
        "    if parsed_args.multi_gpu > 1 and parsed_args.batch_size < parsed_args.multi_gpu:\n",
        "        raise ValueError(\n",
        "            \"Batch size ({}) must be equal to or higher than the number of GPUs ({})\".format(parsed_args.batch_size,\n",
        "                                                                                             parsed_args.multi_gpu))\n",
        "\n",
        "    if parsed_args.multi_gpu > 1 and parsed_args.snapshot:\n",
        "        raise ValueError(\n",
        "            \"Multi GPU training ({}) and resuming from snapshots ({}) is not supported.\".format(parsed_args.multi_gpu,\n",
        "                                                                                                parsed_args.snapshot))\n",
        "\n",
        "    if parsed_args.multi_gpu > 1 and not parsed_args.multi_gpu_force:\n",
        "        raise ValueError(\"Multi-GPU support is experimental, use at own risk! Run with --multi-gpu-force if you wish to continue.\")\n",
        "\n",
        "    if 'resnet' not in parsed_args.backbone:\n",
        "        warnings.warn('Using experimental backbone {}. Only resnet50 has been properly tested.'.format(parsed_args.backbone))\n",
        "\n",
        "    return parsed_args\n",
        "\n",
        "\n",
        "def parse_args(args):\n",
        "    \"\"\" Parse the arguments.\n",
        "    \"\"\"\n",
        "    parser     = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
        "    subparsers = parser.add_subparsers(help='Arguments for specific dataset types.', dest='dataset_type')\n",
        "    subparsers.required = True\n",
        "\n",
        "    coco_parser = subparsers.add_parser('coco')\n",
        "    coco_parser.add_argument('coco_path', help='Path to dataset directory (ie. /tmp/COCO).')\n",
        "\n",
        "    pascal_parser = subparsers.add_parser('pascal')\n",
        "    pascal_parser.add_argument('pascal_path', help='Path to dataset directory (ie. /tmp/VOCdevkit).')\n",
        "    pascal_parser.add_argument('--image-extension',   help='Declares the dataset images\\' extension.', default='.jpg')\n",
        "\n",
        "    kitti_parser = subparsers.add_parser('kitti')\n",
        "    kitti_parser.add_argument('kitti_path', help='Path to dataset directory (ie. /tmp/kitti).')\n",
        "\n",
        "    def csv_list(string):\n",
        "        return string.split(',')\n",
        "\n",
        "    oid_parser = subparsers.add_parser('oid')\n",
        "    oid_parser.add_argument('main_dir', help='Path to dataset directory.')\n",
        "    oid_parser.add_argument('--version',  help='The current dataset version is v4.', default='v4')\n",
        "    oid_parser.add_argument('--labels-filter',  help='A list of labels to filter.', type=csv_list, default=None)\n",
        "    oid_parser.add_argument('--annotation-cache-dir', help='Path to store annotation cache.', default='.')\n",
        "    oid_parser.add_argument('--parent-label', help='Use the hierarchy children of this label.', default=None)\n",
        "\n",
        "    csv_parser = subparsers.add_parser('csv')\n",
        "    csv_parser.add_argument('annotations', help='Path to CSV file containing annotations for training.')\n",
        "    csv_parser.add_argument('classes', help='Path to a CSV file containing class label mapping.')\n",
        "    csv_parser.add_argument('--val-annotations', help='Path to CSV file containing annotations for validation (optional).')\n",
        "\n",
        "    group = parser.add_mutually_exclusive_group()\n",
        "    group.add_argument('--snapshot',          help='Resume training from a snapshot.')\n",
        "    group.add_argument('--imagenet-weights',  help='Initialize the model with pretrained imagenet weights. This is the default behaviour.', action='store_const', const=True, default=True)\n",
        "    group.add_argument('--weights',           help='Initialize the model with weights from a file.')\n",
        "    group.add_argument('--no-weights',        help='Don\\'t initialize the model with any weights.', dest='imagenet_weights', action='store_const', const=False)\n",
        "    parser.add_argument('--backbone',         help='Backbone model used by retinanet.', default='resnet50', type=str)\n",
        "    parser.add_argument('--batch-size',       help='Size of the batches.', default=1, type=int)\n",
        "    parser.add_argument('--gpu',              help='Id of the GPU to use (as reported by nvidia-smi).', type=int)\n",
        "    parser.add_argument('--multi-gpu',        help='Number of GPUs to use for parallel processing.', type=int, default=0)\n",
        "    parser.add_argument('--multi-gpu-force',  help='Extra flag needed to enable (experimental) multi-gpu support.', action='store_true')\n",
        "    parser.add_argument('--initial-epoch',    help='Epoch from which to begin the train, useful if resuming from snapshot.', type=int, default=0)\n",
        "    parser.add_argument('--epochs',           help='Number of epochs to train.', type=int, default=50)\n",
        "    parser.add_argument('--steps',            help='Number of steps per epoch.', type=int, default=10000)\n",
        "    parser.add_argument('--lr',               help='Learning rate.', type=float, default=1e-5)\n",
        "    parser.add_argument('--snapshot-path',    help='Path to store snapshots of models during training (defaults to \\'./snapshots\\')', default='./snapshots')\n",
        "    parser.add_argument('--tensorboard-dir',  help='Log directory for Tensorboard output', default='')  # default='./logs') => https://github.com/tensorflow/tensorflow/pull/34870\n",
        "    parser.add_argument('--no-snapshots',     help='Disable saving snapshots.', dest='snapshots', action='store_false')\n",
        "    parser.add_argument('--no-evaluation',    help='Disable per epoch evaluation.', dest='evaluation', action='store_false')\n",
        "    parser.add_argument('--freeze-backbone',  help='Freeze training of backbone layers.', action='store_true')\n",
        "    parser.add_argument('--random-transform', help='Randomly transform image and annotations.', action='store_true')\n",
        "    parser.add_argument('--image-min-side',   help='Rescale the image so the smallest side is min_side.', type=int, default=800)\n",
        "    parser.add_argument('--image-max-side',   help='Rescale the image if the largest side is larger than max_side.', type=int, default=1333)\n",
        "    parser.add_argument('--no-resize',        help='Don''t rescale the image.', action='store_true')\n",
        "    parser.add_argument('--config',           help='Path to a configuration parameters .ini file.')\n",
        "    parser.add_argument('--weighted-average', help='Compute the mAP using the weighted average of precisions among classes.', action='store_true')\n",
        "    parser.add_argument('--compute-val-loss', help='Compute validation loss during training', dest='compute_val_loss', action='store_true')\n",
        "    parser.add_argument('--reduce-lr-patience', help='Reduce learning rate after validation loss decreases over reduce_lr_patience epochs', type=int, default=2)\n",
        "    parser.add_argument('--reduce-lr-factor', help='When learning rate is reduced due to reduce_lr_patience, multiply by reduce_lr_factor', type=float, default=0.1)\n",
        "\n",
        "    # Fit generator arguments\n",
        "    parser.add_argument('--multiprocessing',  help='Use multiprocessing in fit_generator.', action='store_true')\n",
        "    parser.add_argument('--workers',          help='Number of generator workers.', type=int, default=1)\n",
        "    parser.add_argument('--max-queue-size',   help='Queue length for multiprocessing workers in fit_generator.', type=int, default=10)\n",
        "\n",
        "    return check_args(parser.parse_args(args))\n",
        "\n",
        "\n",
        "def main(args=None):\n",
        "    # parse arguments\n",
        "    if args is None:\n",
        "        args = sys.argv[1:]\n",
        "    args = parse_args(args)\n",
        "\n",
        "    # create object that stores backbone information\n",
        "    backbone = models.backbone(args.backbone)\n",
        "\n",
        "    # make sure keras and tensorflow are the minimum required version\n",
        "    check_keras_version()\n",
        "    check_tf_version()\n",
        "\n",
        "    # optionally choose specific GPU\n",
        "    if args.gpu is not None:\n",
        "        setup_gpu(args.gpu)\n",
        "\n",
        "    # optionally load config parameters\n",
        "    if args.config:\n",
        "        args.config = read_config_file(args.config)\n",
        "\n",
        "    # create the generators\n",
        "    train_generator, validation_generator = create_generators(args, backbone.preprocess_image)\n",
        "\n",
        "    # create the model\n",
        "    if args.snapshot is not None:\n",
        "        print('Loading model, this may take a second...')\n",
        "        model            = models.load_model(args.snapshot, backbone_name=args.backbone)\n",
        "        training_model   = model\n",
        "        anchor_params    = None\n",
        "        pyramid_levels   = None\n",
        "        if args.config and 'anchor_parameters' in args.config:\n",
        "            anchor_params = parse_anchor_parameters(args.config)\n",
        "        if args.config and 'pyramid_levels' in args.config:\n",
        "            pyramid_levels = parse_pyramid_levels(args.config)\n",
        "\n",
        "        prediction_model = retinanet_bbox(model=model, anchor_params=anchor_params, pyramid_levels=pyramid_levels)\n",
        "    else:\n",
        "        weights = args.weights\n",
        "        # default to imagenet if nothing else is specified\n",
        "        if weights is None and args.imagenet_weights:\n",
        "            weights = backbone.download_imagenet()\n",
        "\n",
        "        print('Creating model, this may take a second...')\n",
        "        model, training_model, prediction_model = create_models(\n",
        "            backbone_retinanet=backbone.retinanet,\n",
        "            num_classes=train_generator.num_classes(),\n",
        "            weights=weights,\n",
        "            multi_gpu=args.multi_gpu,\n",
        "            freeze_backbone=args.freeze_backbone,\n",
        "            lr=args.lr,\n",
        "            config=args.config\n",
        "        )\n",
        "\n",
        "    # print model summary\n",
        "    print(model.summary())\n",
        "\n",
        "    # this lets the generator compute backbone layer shapes using the actual backbone model\n",
        "    if 'vgg' in args.backbone or 'densenet' in args.backbone:\n",
        "        train_generator.compute_shapes = make_shapes_callback(model)\n",
        "        if validation_generator:\n",
        "            validation_generator.compute_shapes = train_generator.compute_shapes\n",
        "\n",
        "    # create the callbacks\n",
        "    callbacks = create_callbacks(\n",
        "        model,\n",
        "        training_model,\n",
        "        prediction_model,\n",
        "        validation_generator,\n",
        "        args,\n",
        "    )\n",
        "\n",
        "    if not args.compute_val_loss:\n",
        "        validation_generator = None\n",
        "\n",
        "    # start training\n",
        "    return training_model.fit_generator(\n",
        "        generator=train_generator,\n",
        "        steps_per_epoch=args.steps,\n",
        "        epochs=args.epochs,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks,\n",
        "        workers=args.workers,\n",
        "        use_multiprocessing=args.multiprocessing,\n",
        "        max_queue_size=args.max_queue_size,\n",
        "        validation_data=validation_generator,\n",
        "        initial_epoch=args.initial_epoch\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/keras-retinanet/keras_retinanet/bin/train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8JfC8BpQiWr",
        "colab_type": "text"
      },
      "source": [
        "#### 1) loading data, by running data_load.py file with proper input Test and Train file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7xTgaMZUCsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00fb9478-ab3e-4b38-ac76-9bc28f77207a"
      },
      "source": [
        "!python3 data_load.py --train '/content/drive/My Drive/Data/Train/' --test '/content/drive/My Drive/Data/Test/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbieAyVJTJwp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "343320b1-3d0c-474e-f989-68c632e05135"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations.csv  \u001b[0m\u001b[01;34mexamples\u001b[0m/                  requirements.txt\n",
            "\u001b[01;34mbuild\u001b[0m/           \u001b[01;34mimages\u001b[0m/                    setup.cfg\n",
            "classes.csv      \u001b[01;34mkeras_retinanet\u001b[0m/           setup.py\n",
            "CONTRIBUTORS.md  \u001b[01;34mkeras_retinanet.egg-info\u001b[0m/  \u001b[01;34msnapshots\u001b[0m/\n",
            "data_load.py     LICENSE                    \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdist\u001b[0m/            README.md                  val_annotations.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTjiyytQRHoM",
        "colab_type": "text"
      },
      "source": [
        "#### 2) Train data, by running train.py file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKSRg9xsSkTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "8c149021-3193-4da3-9b88-00fc8cdbf6cd"
      },
      "source": [
        "!python3 setup.py build_ext --inplace"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build_ext\n",
            "skipping 'keras_retinanet/utils/compute_overlap.c' Cython extension (up-to-date)\n",
            "copying build/lib.linux-x86_64-3.6/keras_retinanet/utils/compute_overlap.cpython-36m-x86_64-linux-gnu.so -> keras_retinanet/utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNLwHElUTo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a78322f-5b6e-4ff5-a4d1-dfb44f49dd3e"
      },
      "source": [
        "!python /content/keras-retinanet/keras_retinanet/bin/train.py --backbone='resnet50' --weights /content/keras-retinanet/snapshots/resnet50_coco_best_v2.0.1.h5 --random-transform --gpu=0 --batch-size=4 --steps 600 --epochs 12 --image-min-side=500 --image-max-side=500 --lr 0.001 --weighted-average --compute-val-loss csv /content/keras-retinanet/annotations.csv /content/keras-retinanet/classes.csv \\\n",
        "--val-annotations /content/keras-retinanet/val_annotations.csv"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-08-03 13:44:07.347113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 13:44:09.539533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-03 13:44:09.629062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:09.629712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-03 13:44:09.629770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 13:44:09.867576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-03 13:44:10.016668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-03 13:44:10.042353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-03 13:44:10.337098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-03 13:44:10.377615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-03 13:44:10.925484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 13:44:10.925699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:10.926466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:10.927106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-03 13:44:10.956696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-08-03 13:44:10.956922: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c4abc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-03 13:44:10.956955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-03 13:44:11.138861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:11.139660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c4ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-03 13:44:11.139691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-03 13:44:11.141415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:11.141941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-03 13:44:11.142013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 13:44:11.142066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-03 13:44:11.142107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-03 13:44:11.142127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-03 13:44:11.142147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-03 13:44:11.142165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-03 13:44:11.142185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 13:44:11.142262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:11.142863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:11.143393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-03 13:44:11.147563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 13:44:17.951571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-03 13:44:17.951629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-08-03 13:44:17.951650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-08-03 13:44:17.957669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:17.958291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 13:44:17.958875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "1 Physical GPUs, 1 Logical GPUs\n",
            "Creating model, this may take a second...\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 27) vs (720, 256, 3, 3)).\n",
            "  weight_values[i].shape))\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:1319: UserWarning: Skipping loading of weights for layer classification_submodel due to mismatch in shape ((27,) vs (720,)).\n",
            "  weight_values[i].shape))\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
            "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
            "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
            "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
            "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
            "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
            "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
            "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
            "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
            "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
            "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
            "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
            "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
            "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
            "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
            "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
            "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
            "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
            "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
            "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
            "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
            "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
            "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
            "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
            "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
            "      dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
            "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
            "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
            "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
            "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
            "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
            "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
            "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
            "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
            "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
            "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
            "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
            "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
            "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
            "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
            "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
            "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n",
            "Model: \"retinanet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "padding_conv1 (ZeroPadding2D)   (None, None, None, 3 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, None, None, 6 9408        padding_conv1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              \n",
            "                                                                 res2a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              \n",
            "                                                                 res2b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              \n",
            "                                                                 res3a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              \n",
            "                                                                 res3b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              \n",
            "                                                                 res3c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              \n",
            "                                                                 res4a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              \n",
            "                                                                 res4b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              \n",
            "                                                                 res4c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              \n",
            "                                                                 res4d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              \n",
            "                                                                 res4e_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              \n",
            "                                                                 res5a_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              \n",
            "                                                                 res5b_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 \n",
            "                                                                 res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               \n",
            "                                                                 C4_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  \n",
            "                                                                 res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               \n",
            "                                                                 C3_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "classification_submodel (Model) (None, None, 3)      2422555     P3[0][0]                         \n",
            "                                                                 P4[0][0]                         \n",
            "                                                                 P5[0][0]                         \n",
            "                                                                 P6[0][0]                         \n",
            "                                                                 P7[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        \n",
            "                                                                 regression_submodel[2][0]        \n",
            "                                                                 regression_submodel[3][0]        \n",
            "                                                                 regression_submodel[4][0]        \n",
            "                                                                 regression_submodel[5][0]        \n",
            "__________________________________________________________________________________________________\n",
            "classification (Concatenate)    (None, None, 3)      0           classification_submodel[1][0]    \n",
            "                                                                 classification_submodel[2][0]    \n",
            "                                                                 classification_submodel[3][0]    \n",
            "                                                                 classification_submodel[4][0]    \n",
            "                                                                 classification_submodel[5][0]    \n",
            "==================================================================================================\n",
            "Total params: 36,424,447\n",
            "Trainable params: 36,318,207\n",
            "Non-trainable params: 106,240\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/12\n",
            "2020-08-03 13:47:58.744659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 13:48:03.894221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.7625 - regression_loss: 2.1779 - classification_loss: 0.5846/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 293s 489ms/step - loss: 2.7617 - regression_loss: 2.1773 - classification_loss: 0.5845 - val_loss: 3.4753 - val_regression_loss: 2.4650 - val_classification_loss: 0.7303\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:28 Time:  0:00:28\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0297\n",
            "45 instances of class table with average precision: 0.0307\n",
            "26 instances of class vase with average precision: 0.1060\n",
            "mAP: 0.0382\n",
            "\n",
            "Epoch 00001: saving model to ./snapshots/resnet50_csv_01.h5\n",
            "Epoch 2/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.5239 - regression_loss: 2.0345 - classification_loss: 0.4894/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 216s 360ms/step - loss: 2.5246 - regression_loss: 2.0351 - classification_loss: 0.4895 - val_loss: 2.9960 - val_regression_loss: 2.4841 - val_classification_loss: 0.6198\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0468\n",
            "45 instances of class table with average precision: 0.0327\n",
            "26 instances of class vase with average precision: 0.0956\n",
            "mAP: 0.0495\n",
            "\n",
            "Epoch 00002: saving model to ./snapshots/resnet50_csv_02.h5\n",
            "Epoch 3/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.3602 - regression_loss: 1.9179 - classification_loss: 0.4423/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 216s 359ms/step - loss: 2.3604 - regression_loss: 1.9181 - classification_loss: 0.4423 - val_loss: 3.3179 - val_regression_loss: 2.3926 - val_classification_loss: 0.5771\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:03 Time:  0:00:03\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0916\n",
            "45 instances of class table with average precision: 0.0958\n",
            "26 instances of class vase with average precision: 0.2887\n",
            "mAP: 0.1139\n",
            "\n",
            "Epoch 00003: saving model to ./snapshots/resnet50_csv_03.h5\n",
            "Epoch 4/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.2397 - regression_loss: 1.8353 - classification_loss: 0.4044/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 214s 357ms/step - loss: 2.2390 - regression_loss: 1.8346 - classification_loss: 0.4043 - val_loss: 3.4107 - val_regression_loss: 2.4002 - val_classification_loss: 0.6283\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0719\n",
            "45 instances of class table with average precision: 0.1017\n",
            "26 instances of class vase with average precision: 0.3697\n",
            "mAP: 0.1101\n",
            "\n",
            "Epoch 00004: saving model to ./snapshots/resnet50_csv_04.h5\n",
            "Epoch 5/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.1376 - regression_loss: 1.7583 - classification_loss: 0.3793/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 215s 358ms/step - loss: 2.1377 - regression_loss: 1.7582 - classification_loss: 0.3794 - val_loss: 2.7233 - val_regression_loss: 2.4025 - val_classification_loss: 0.5608\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.1006\n",
            "45 instances of class table with average precision: 0.1205\n",
            "26 instances of class vase with average precision: 0.4575\n",
            "mAP: 0.1433\n",
            "\n",
            "Epoch 00005: saving model to ./snapshots/resnet50_csv_05.h5\n",
            "Epoch 6/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.0453 - regression_loss: 1.6868 - classification_loss: 0.3585/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 215s 358ms/step - loss: 2.0455 - regression_loss: 1.6870 - classification_loss: 0.3585 - val_loss: 3.1305 - val_regression_loss: 2.4549 - val_classification_loss: 0.5724\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0959\n",
            "45 instances of class table with average precision: 0.0968\n",
            "26 instances of class vase with average precision: 0.3728\n",
            "mAP: 0.1264\n",
            "\n",
            "Epoch 00006: saving model to ./snapshots/resnet50_csv_06.h5\n",
            "Epoch 7/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 2.0127 - regression_loss: 1.6681 - classification_loss: 0.3446/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 215s 358ms/step - loss: 2.0125 - regression_loss: 1.6678 - classification_loss: 0.3447 - val_loss: 2.9870 - val_regression_loss: 2.5352 - val_classification_loss: 0.6265\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:04 Time:  0:00:04\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0672\n",
            "45 instances of class table with average precision: 0.1166\n",
            "26 instances of class vase with average precision: 0.4134\n",
            "mAP: 0.1144\n",
            "\n",
            "Epoch 00007: saving model to ./snapshots/resnet50_csv_07.h5\n",
            "Epoch 8/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 1.9696 - regression_loss: 1.6357 - classification_loss: 0.3339/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 215s 358ms/step - loss: 1.9691 - regression_loss: 1.6353 - classification_loss: 0.3338 - val_loss: 3.0350 - val_regression_loss: 2.3676 - val_classification_loss: 0.6381\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:03 Time:  0:00:03\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.1075\n",
            "45 instances of class table with average precision: 0.1124\n",
            "26 instances of class vase with average precision: 0.4094\n",
            "mAP: 0.1414\n",
            "\n",
            "Epoch 00008: saving model to ./snapshots/resnet50_csv_08.h5\n",
            "Epoch 9/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 1.9201 - regression_loss: 1.6011 - classification_loss: 0.3190/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 215s 358ms/step - loss: 1.9200 - regression_loss: 1.6010 - classification_loss: 0.3190 - val_loss: 3.4709 - val_regression_loss: 2.4671 - val_classification_loss: 0.6719\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:03 Time:  0:00:03\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0975\n",
            "45 instances of class table with average precision: 0.1659\n",
            "26 instances of class vase with average precision: 0.2774\n",
            "mAP: 0.1301\n",
            "\n",
            "Epoch 00009: saving model to ./snapshots/resnet50_csv_09.h5\n",
            "Epoch 10/12\n",
            "599/600 [============================>.] - ETA: 0s - loss: 1.8999 - regression_loss: 1.5877 - classification_loss: 0.3122/content/keras-retinanet/keras_retinanet/bin/../../keras_retinanet/preprocessing/generator.py:181: UserWarning: Image /content/drive/My Drive/Data/Test/table17.jpg with id 53 (shape (575, 919, 3)) contains the following invalid boxes: [[  29.   49. 1265.  694.]].\n",
            "  annotations['bboxes'][invalid_indices, :]\n",
            "600/600 [==============================] - 214s 357ms/step - loss: 1.8996 - regression_loss: 1.5875 - classification_loss: 0.3121 - val_loss: 3.4431 - val_regression_loss: 2.5546 - val_classification_loss: 0.7090\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:03 Time:  0:00:03\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0831\n",
            "45 instances of class table with average precision: 0.1778\n",
            "26 instances of class vase with average precision: 0.2571\n",
            "mAP: 0.1200\n",
            "\n",
            "Epoch 00010: saving model to ./snapshots/resnet50_csv_10.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g2vI_R_v7--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python /content/keras-retinanet/keras_retinanet/bin/train.py --backbone='resnet50' --weights /content/keras-retinanet/snapshots/resnet50_coco_best_v2.0.1.h5 --random-transform --gpu=0 --batch-size=8 --steps 800 --epochs 10 --image-min-side=500 --image-max-side=500 --lr 0.001 --weighted-average --compute-val-loss csv /content/keras-retinanet/annotations.csv /content/keras-retinanet/classes.csv \\\n",
        "# --val-annotations /content/keras-retinanet/val_annotations.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7B68wZZTHOR",
        "colab_type": "text"
      },
      "source": [
        "#### 3) evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVIX_7pRTNBO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aaefe19-f11d-40dc-cc25-89275d0fcc56"
      },
      "source": [
        "!python ./keras_retinanet/bin/evaluate.py --backbone='resnet50' --iou-threshold 0.50 --image-min-side 600 --image-max-side 1000 csv val_annotations.csv classes.csv /content/keras-retinanet/snapshots/resnet50_csv_08.h5 --convert-model "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-08-03 14:44:34.483611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Loading model, this may take a second...\n",
            "2020-08-03 14:44:36.057719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-03 14:44:36.096269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.096852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-03 14:44:36.096898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 14:44:36.111380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-03 14:44:36.120748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-03 14:44:36.128825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-03 14:44:36.141721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-03 14:44:36.147549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-03 14:44:36.173122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 14:44:36.173252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.173910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.174440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-03 14:44:36.179638: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-08-03 14:44:36.179828: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2124d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-03 14:44:36.179856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-03 14:44:36.286134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.286779: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2124f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-03 14:44:36.286807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-03 14:44:36.287047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.287588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-03 14:44:36.287639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 14:44:36.287686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-03 14:44:36.287709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-03 14:44:36.287732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-03 14:44:36.287750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-03 14:44:36.287771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-03 14:44:36.287793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 14:44:36.287861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.288399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.288873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-03 14:44:36.288952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 14:44:36.788471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-03 14:44:36.788529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-08-03 14:44:36.788541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-08-03 14:44:36.788779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.789380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:44:36.789871: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-03 14:44:36.789914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13970 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
            "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
            "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
            "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
            "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
            "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
            "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
            "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
            "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
            "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
            "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
            "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
            "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
            "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
            "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
            "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
            "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
            "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
            "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
            "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
            "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
            "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
            "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
            "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
            "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
            "      dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
            "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
            "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
            "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
            "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
            "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
            "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
            "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
            "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
            "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
            "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
            "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
            "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
            "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
            "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
            "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
            "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n",
            "Running network: N/A% (0 of 54) |         | Elapsed Time: 0:00:00 ETA:  --:--:--2020-08-03 14:44:47.616187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 14:44:49.320510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Running network: 100% (54 of 54) |########| Elapsed Time: 0:00:32 Time:  0:00:32\n",
            "Parsing annotations: 100% (54 of 54) |####| Elapsed Time: 0:00:00 Time:  0:00:00\n",
            "167 instances of class chair with average precision: 0.0920\n",
            "45 instances of class table with average precision: 0.0792\n",
            "26 instances of class vase with average precision: 0.3248\n",
            "Inference time for 54 images: 0.5845\n",
            "mAP using the weighted average of precisions among classes: 0.1150\n",
            "mAP: 0.1654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m03AvuYRykWc",
        "colab_type": "text"
      },
      "source": [
        "#### 4) inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMHruSYXyrHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9be7fb08-f59f-4193-b152-82770e3a8875"
      },
      "source": [
        "!python ./keras_retinanet/bin/convert_model.py  ./snapshots/resnet50_csv_08.h5 ./inference/Model1305r2-CSV08-n3d3nc.h5 --backbone='resnet50' --nms-threshold=0.15 --max-detections=300 --no-class-specific-filter"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-08-03 14:57:21.966473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 14:57:23.409601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-03 14:57:23.442497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:57:23.443066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-03 14:57:23.443116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-03 14:57:23.444708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-03 14:57:23.446320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-03 14:57:23.446638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-03 14:57:23.448445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-03 14:57:23.449323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-03 14:57:23.452779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-03 14:57:23.452891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:57:23.453442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-03 14:57:23.453926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-03 14:57:23.535745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
            "2020-08-03 14:57:23.535927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x134cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-03 14:57:23.535961: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-03 14:57:23.537043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-03 14:57:23.537070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      \n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-22.627417, -11.313708,  22.627417,  11.313708],\n",
            "       [-28.50876 , -14.25438 ,  28.50876 ,  14.25438 ],\n",
            "       [-35.918785, -17.959393,  35.918785,  17.959393],\n",
            "       [-16.      , -16.      ,  16.      ,  16.      ],\n",
            "       [-20.158737, -20.158737,  20.158737,  20.158737],\n",
            "       [-25.398417, -25.398417,  25.398417,  25.398417],\n",
            "       [-11.313708, -22.627417,  11.313708,  22.627417],\n",
            "       [-14.25438 , -28.50876 ,  14.25438 ,  28.50876 ],\n",
            "       [-17.959393, -35.918785,  17.959393,  35.918785]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-45.254833, -22.627417,  45.254833,  22.627417],\n",
            "       [-57.01752 , -28.50876 ,  57.01752 ,  28.50876 ],\n",
            "       [-71.83757 , -35.918785,  71.83757 ,  35.918785],\n",
            "       [-32.      , -32.      ,  32.      ,  32.      ],\n",
            "       [-40.317474, -40.317474,  40.317474,  40.317474],\n",
            "       [-50.796833, -50.796833,  50.796833,  50.796833],\n",
            "       [-22.627417, -45.254833,  22.627417,  45.254833],\n",
            "       [-28.50876 , -57.01752 ,  28.50876 ,  57.01752 ],\n",
            "       [-35.918785, -71.83757 ,  35.918785,  71.83757 ]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[ -90.50967 ,  -45.254833,   90.50967 ,   45.254833],\n",
            "       [-114.03504 ,  -57.01752 ,  114.03504 ,   57.01752 ],\n",
            "       [-143.67514 ,  -71.83757 ,  143.67514 ,   71.83757 ],\n",
            "       [ -64.      ,  -64.      ,   64.      ,   64.      ],\n",
            "       [ -80.63495 ,  -80.63495 ,   80.63495 ,   80.63495 ],\n",
            "       [-101.593666, -101.593666,  101.593666,  101.593666],\n",
            "       [ -45.254833,  -90.50967 ,   45.254833,   90.50967 ],\n",
            "       [ -57.01752 , -114.03504 ,   57.01752 ,  114.03504 ],\n",
            "       [ -71.83757 , -143.67514 ,   71.83757 ,  143.67514 ]],\n",
            "      dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-181.01933,  -90.50967,  181.01933,   90.50967],\n",
            "       [-228.07008, -114.03504,  228.07008,  114.03504],\n",
            "       [-287.35028, -143.67514,  287.35028,  143.67514],\n",
            "       [-128.     , -128.     ,  128.     ,  128.     ],\n",
            "       [-161.2699 , -161.2699 ,  161.2699 ,  161.2699 ],\n",
            "       [-203.18733, -203.18733,  203.18733,  203.18733],\n",
            "       [ -90.50967, -181.01933,   90.50967,  181.01933],\n",
            "       [-114.03504, -228.07008,  114.03504,  228.07008],\n",
            "       [-143.67514, -287.35028,  143.67514,  287.35028]], dtype=float32)> anchors\n",
            "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32, numpy=\n",
            "array([[-362.03867, -181.01933,  362.03867,  181.01933],\n",
            "       [-456.14017, -228.07008,  456.14017,  228.07008],\n",
            "       [-574.70056, -287.35028,  574.70056,  287.35028],\n",
            "       [-256.     , -256.     ,  256.     ,  256.     ],\n",
            "       [-322.5398 , -322.5398 ,  322.5398 ,  322.5398 ],\n",
            "       [-406.37466, -406.37466,  406.37466,  406.37466],\n",
            "       [-181.01933, -362.03867,  181.01933,  362.03867],\n",
            "       [-228.07008, -456.14017,  228.07008,  456.14017],\n",
            "       [-287.35028, -574.70056,  287.35028,  574.70056]], dtype=float32)> anchors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YDWwC4l1Gw5",
        "colab_type": "text"
      },
      "source": [
        "#### Run detection on example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02t2P2nL13KT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b8ffd8ea-19dd-4fbc-9a7a-e6b4c8a8a434"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "from keras_retinanet.utils.gpu import setup_gpu\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# use this to change which GPU to use\n",
        "gpu = 0\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "setup_gpu(gpu)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmpzII8Q343W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "a0acd1b4-a468-408a-b264-c874f917a3cc"
      },
      "source": [
        "pip install keras-resnet"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-resnet in /usr/local/lib/python3.6/dist-packages/keras_resnet-0.1.0-py3.6.egg (0.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-resnet) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-resnet) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6BiEApr3NMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "6ee2a7da-a96c-40f5-e855-0a9181e71563"
      },
      "source": [
        "model = models.load_model('/content/keras-retinanet/snapshots/resnet50_coco_best_v2.0.1.h5', backbone_name='resnet50')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-27409657b94c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/keras-retinanet/snapshots/resnet50_coco_best_v2.0.1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, backbone_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/__init__.py\u001b[0m in \u001b[0;36mbackbone\u001b[0;34m(backbone_name)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'resnet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'mobilenet'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetBackbone\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras-retinanet/keras_retinanet/models/resnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_resnet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr0OKu271JuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "bfad52b2-34dd-4af6-bd20-5a9a4a1e46d2"
      },
      "source": [
        "# load image\n",
        "image = read_image_bgr('test_image.jpg')\n",
        "\n",
        "# copy to draw on\n",
        "draw = image.copy()\n",
        "draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# preprocess image for network\n",
        "image = preprocess_image(image)\n",
        "image, scale = resize_image(image)\n",
        "\n",
        "# process image\n",
        "start = time.time()\n",
        "boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "print(\"processing time: \", time.time() - start)\n",
        "\n",
        "# correct for image scale\n",
        "boxes /= scale\n",
        "\n",
        "# visualize detections\n",
        "for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "    # scores are sorted so we can break\n",
        "    if score < 0.5:\n",
        "        break\n",
        "        \n",
        "    color = label_color(label)\n",
        "    \n",
        "    b = box.astype(int)\n",
        "    draw_box(draw, b, color=color)\n",
        "    \n",
        "    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "    draw_caption(draw, b, caption)\n",
        "    \n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.axis('off')\n",
        "plt.imshow(draw)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-060273eb41c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processing time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}